# llm-news
https://llm-news.deveugene.de/

Daily top 3 fresh news aggregated by different LLMs

Core flow for generating and commiting the news are in GitHub Action `.github/workflows/news-aggregator.yml`
We are doing 2 calls to Gemini there, the first one, grounded on google search to find 3 the most popular news topics.
The second call is to generate JSON with the information generated by LLMs.

Currently, we have to do 2 calls, because grounded search can't return JSON.
For the JSON generation, we are always using gemini-2.5-flash but can be configured via JSON_CONVERTER_MODEL

After we receive the data, we just commit it to the news folder and push it to the repository.
This way we can use GitHub Pages to serve the data, and we don't need to run any server.

# Contributing

Feel free to contact me, fork, or add a PR, if you want to add some additional functionality.
For now, it's planned to monitor how LLMs will generate news, and extend the generation with more models.

# run new generation locally

1. create .secrets file with the following content:
```
OPENAI_API_KEY=your_openai_api_key
```

2. run `act -W .github/workflows/news-aggregator.yml`

3. to run generation again you need to delete the day in the `news` folder, e.g. `rm -rf news/2025-06-22`

4. List of models can be changed in [model](https://github.com/eugene-taran/llm-news/blob/a3ba540f532ba76f8a1b7a11f92e410bac3f8086/.github/workflows/news-aggregator.yml#L16) parameter, but for now only models that can be grounded on Google Search are supported.

# generate new data for frontend and rebuild

```
cd frontend && yarn frontend:prep
```

name: News Aggregator Workflow
on:
  schedule:
    - cron: '0 16 * * *'  # Runs every day at 18:00 (6pm) UTC
  workflow_dispatch:  # Allows manual trigger
  push:
    branches: [ main ]

env:
  JSON_CONVERTER_MODEL: "gemini-2.5-flash"  # Model used for JSON conversion

jobs:
  # should be possible to call with different modules, for now gemini only as only it supports grounded content
  call-llm:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        model: ["gemini-2.5-flash", "gemini-2.5-pro", "gemini-2.0-flash"]
      fail-fast: false
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Call Gemini API and Store Results
        run: |
          
          # Get current date in YYYY-MM-DD format
          current_date=$(date +%Y-%m-%d)
          model_name="${{ matrix.model }}"
          
          # Create directory structure
          output_dir="news/${current_date}/${model_name}"
          mkdir -p "$output_dir"
          
          echo "Creating output directory: $output_dir"
          
          # Check if model-output.json already exists for this model
          if [ -f "${output_dir}/model-output.json" ]; then
            echo "Output file already exists for ${model_name}, skipping..."
            exit 0
          fi
          
          # Step 1: Get grounded news content (without JSON requirement)
          echo "Step 1: Getting grounded news content..."
          grounded_response=$(curl -s "https://generativelanguage.googleapis.com/v1beta/models/${{ matrix.model }}:generateContent?key=${{ secrets.GEMINI_API_KEY }}" \
            -H 'Content-Type: application/json' \
            -X POST \
            -d '{
              "contents": [{
                "parts": [{
                  "text": "From the past 24 hours find 3 the most popular news articles and write a short summary for each of them. Format each article as: Title: [title], Description: [description], Source: [source], Link: [link] Put each article on a separate line."
                }]
              }],
              "tools": [{
                "google_search": {}
              }],
              "generationConfig": {
                "temperature": 0,
                "candidateCount": 1,
                "maxOutputTokens": 2048
              }
            }')
          
          # Extract the grounded content
          echo "response:"
          grounded_content=$(echo "$grounded_response" | jq -r '.candidates[0].content.parts[0].text' 2>/dev/null)
          echo "$grounded_content"
          
          echo "Grounded content extracted successfully:"
          echo "$grounded_content"
          
          # Step 2: Convert grounded content to JSON format
          echo "Step 2: Converting to JSON format..."
          
          echo "start json generation"
          # Properly escape the grounded content for JSON
          escaped_content=$(echo "$grounded_content" | sed 's/"/\\"/g' | tr '\n' ' ')
          
          # Use jq to build the JSON payload properly
          echo "do a call"
          json_payload=$(jq -n \
            --arg content "$escaped_content" \
            '{
              contents: [{
                parts: [{
                  text: ("Convert the following news content to valid JSON format with the structure {\"articles\": [{\"title\": \"Article Title\", \"description\": \"Brief summary\", \"source\": \"Source name\", \"link\": \"Valid URL\"}]}. You must return only valid JSON, no additional text. You must not include markdown wrapper. News content: " + $content)
                }]
              }],
              generationConfig: {
                temperature: 0,
                candidateCount: 1,
                maxOutputTokens: 2048
              }
            }')
          
          json_response=$(curl -s "https://generativelanguage.googleapis.com/v1beta/models/${{ env.JSON_CONVERTER_MODEL }}:generateContent?key=${{ secrets.GEMINI_API_KEY }}" \
            -H 'Content-Type: application/json' \
            -X POST \
            -d "$json_payload")
          
          echo "Raw JSON response:"
          echo "$json_response"
          
          # Extract the JSON content
          generated_content=$(echo "$json_response" | jq -r '.candidates[0].content.parts[0].text' 2>/dev/null)
          
          echo "JSON content extracted successfully:"
          echo "$generated_content"
          
          # Save the cleaned JSON content to file
          echo "$generated_content" > "${output_dir}/model-output.json"
          
          echo "Content saved to: ${output_dir}/model-output.json"
          
          # Verify the file was created and show its contents
          if [ -f "${output_dir}/model-output.json" ]; then
            echo "File created successfully. Contents:"
            cat "${output_dir}/model-output.json"
          
            # Pretty print if it's valid JSON
            echo "Pretty printed JSON:"
            cat "${output_dir}/model-output.json" | jq '.' 2>/dev/null || echo "Content is not valid JSON"
          else
            echo "Error: File was not created"
          fi

      - name: Commit and Push Results
        if: ${{ !env.ACT }}  # Only run if NOT running with act
        run: |
          # Configure git
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          
          # Add the new files
          git add news/
          
          # Check if there are changes to commit
          if git diff --staged --quiet; then
            echo "No changes to commit"
          else
            # Commit with timestamp
            git commit -m "Add news aggregation for $(date +%Y-%m-%d) - $(date +%H:%M:%S) - ${{ matrix.model }}"
          
            # Retry push with rebase up to 5 times
            max_retries=5
            retry_count=0
          
            while [ $retry_count -lt $max_retries ]; do
              echo "Attempting to push (attempt $((retry_count + 1))/$max_retries)..."
          
              if git push; then
                echo "Push successful!"
                break
              else
                echo "Push failed, rebasing and retrying..."
                retry_count=$((retry_count + 1))
          
                if [ $retry_count -lt $max_retries ]; then
                  # Pull with rebase to get latest changes
                  git pull --rebase origin ${{ github.ref_name }}
          
                  # Wait a random amount of time to reduce conflicts
                  sleep $((RANDOM % 10 + 1))
                else
                  echo "Max retries reached, push failed"
                  exit 1
                fi
              fi
            done
          
            echo "Changes committed and pushed successfully"
          fi
